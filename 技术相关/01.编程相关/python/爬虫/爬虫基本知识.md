#### 爬虫：自动从网络检索数据

#### 爬虫架构通常是分布式的，有控制节点，有实际爬取得节点，比如控制节点可以分配哪些节点处理哪些url

#### HTTP协议请求
请求分类|说明
--|--
GET|GET请求会通过url网址传递信息，可以直接在URL中写上要传递的信息，也可以由表单传递信息。
POST|可以向服务器提交数据，是一种比较主流也比较安全的数据传递方式，比如登录时，用POST请求传递数据
PUT|请求服务器存储一个资源，通常要指定存储的位置
DELETE|请求服务器删除一个资源
HEAD|请求获取对应HTTP请求报头信息
OPTIONS|可以获得当前URL所支持的请求类型
TRACE|用于测试和诊断

#### Cookie
HTTP协议是一个无状态协议（无法维持会话之间状态的协议），假如登录成功了，当我们访问该网站其他网页时登录状态会消失，还需要再登录一次。因此我们需要将会话信息保留下来，保留的方式有两种：Cookie和Session。
- 如果是通过Cookie保存会话信息，此时会将所有的会话信息保存在客户端。
- 如果是通过Session保存会话信息，会将对应的会话信息保存在服务端，但是服务端会给客户端发SessionID等信息，这些信息一般保留在客户端的Cookie中。

**技巧：用F12键可以打开浏览器的调试窗口，看到具体的信息**

#### 爬虫的模块
- 初始URL集合
- URL队列
- 页面爬行模块
- 页面分析模块
- 页面数据库
- 链接过滤模块
- 内容评价模块
- 链接评价模块
- LVS列表（标签/数值集合）
- 表单分析器
- 表单处理器
- 响应分析器

#### 搜索引擎爬虫数据库
- 原始数据库
- 索引数据库
- 用户日志数据库

#### 爬行策略
- 基于内容评价的爬行策略
- 基于链接评价的爬行策略
- 基于增强学习的爬行策略
- 基于语境图的爬行策略

**大站**： 如果某个网站的网页数量多，我们称其为大站
**反向连接数**： 指的是一个网页被其他网页指向的次数，这个次数在一定程度上代表着该网页被其他网页的推荐次数。

#### 网页更新策略
- 用户体验策略
- 历史数据策略
- 聚类分析策略：我们认为具有类似属性的网页其更新频率也类似

#### 网页分析算法
- 基于用户行为
- 基于网络拓扑
- 基于网页内容

#### Robots协议
一个爬虫访问一个网站的时候，首先会根据该网站下的Robots.txt文件来确定可爬取得网页范围。Robots协议是需要网络爬虫共同遵守的协议，对于一些禁止的URL地址，网络爬虫则不应该爬取访问。
